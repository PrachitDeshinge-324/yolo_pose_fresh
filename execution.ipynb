{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir input\n",
    "%cd input\n",
    "!gdown --fuzzy \"https://drive.google.com/file/d/1YLSJFFBxDbECtKvWPaqoxCdRRSzJsz_1/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/iiitdwd/Prachit/yolo_pose_fresh\n",
    "!gdown --folder --fuzzy \"https://drive.google.com/drive/folders/1jqAtaHGO3nsa_d6d_bKYg9YRZ9YC9DU8?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b393de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf results/\n",
    "!rm -rf __pycache__\n",
    "!rm -rf utils/__pycache__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0063a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps, Pose device: cpu\n",
      "Initializing components...\n",
      "Using TransReID for robust re-identification and tracking\n",
      "Loading TransReID weights from weights/transreid_vitbase.pth...\n",
      "using stride: 16, and patch number is num_y16 * num_x8\n",
      "TransReID model has 86,515,432 parameters\n",
      "TransReID Model Architecture:\n",
      "TransReID\n",
      "  - patch_embed: PatchEmbed\n",
      "  - pos_drop: Dropout\n",
      "  - blocks: ModuleList\n",
      "  - norm: LayerNorm\n",
      "  - fc: Linear\n",
      "  - gem: GeneralizedMeanPooling\n",
      "Interpolating position embeddings:\n",
      "  - Checkpoint grid: 21×10 (210 patches)\n",
      "  - Model grid: 16×8 (128 patches)\n",
      "TransReID weights loaded successfully.\n",
      "TransReID model loaded successfully on mps\n",
      "Loading YOLO11 segmentation model...\n",
      "YOLO11 segmentation model loaded on mps\n",
      "Loading OpenGait embedder...\n",
      "Loaded weights from weights/GaitBase_DA-60000.pt\n",
      "Writing output to results/MyMovie.mp4\n",
      "Starting enhanced video processing with OpenGait features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/200 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/self/Working/Fresh/main.py:475\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- ID merges applied: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(merged_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/self/Working/Fresh/main.py:383\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Process the video\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m \u001b[43mvideo_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo processing complete. Features collected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# Print OpenGait statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/self/Working/Fresh/utils/video_processor.py:60\u001b[0m, in \u001b[0;36mVideoProcessor.process_video\u001b[0;34m(self, process_frame_func)\u001b[0m\n\u001b[1;32m     57\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m current_time\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Process frame\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m processed_frame \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_frame_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Write or display frame\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter:\n",
      "File \u001b[0;32m~/self/Working/Fresh/main.py:270\u001b[0m, in \u001b[0;36mmain.<locals>.process_frame\u001b[0;34m(frame, frame_count, fps)\u001b[0m\n\u001b[1;32m    267\u001b[0m tracked_detections \u001b[38;5;241m=\u001b[39m detector_tracker\u001b[38;5;241m.\u001b[39mdetect_and_track(frame)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# 2. Process each detection\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m tracked_detections:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(detection, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m detection\u001b[38;5;241m.\u001b[39mtrack_id \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "%run main.py \\\n",
    "  --video \"../Person_New/input/My Movie.mp4\" \\\n",
    "  --output \"results/MyMovie.mp4\" \\\n",
    "  --results_dir \"results\" \\\n",
    "  --save_bbox_info \\\n",
    "  --merge_ids \\\n",
    "  --use_transreid \\\n",
    "  --save_video \\\n",
    "  --start_frame 0 \\\n",
    "  --end_frame 200 \\\n",
    "  --display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54160f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
